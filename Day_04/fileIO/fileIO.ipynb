{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "3\n"
                    ]
                }
            ],
            "source": [
                "import re\n",
                "start_with_hash = 0\n",
                "with open(\"sample.txt\" , \"r+\") as f:\n",
                "    for line in f:\n",
                "        if (re.match('^#' , line)):\n",
                "            start_with_hash += 1\n",
                "\n",
                "print(start_with_hash)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "Counter({'example.com': 2,\n",
                            "         'example.org': 1,\n",
                            "         'example.net': 1,\n",
                            "         'example.edu': 1})"
                        ]
                    },
                    "execution_count": 3,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "from collections import Counter\n",
                "def get_domain(email_address):\n",
                "    ''' return the domain from email address'''\n",
                "    return email_address.lower().split('@')[-1]\n",
                "\n",
                "with open('sample.txt' , 'r') as f:\n",
                "        \n",
                "    domain_counter = Counter(get_domain(line.strip()) for line in f if '@' in line)\n",
                "\n",
                "domain_counter"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Delimited FIles \n",
                "The hypothetical email addresses file we just processed had one address per line. More\n",
                "frequently you’ll work with files with lots of data on each line. These files are very often\n",
                "either comma-separated or tab-separated. Each line has several fields, with a comma (or a\n",
                "tab) indicating where one field ends and the next field starts.\n",
                "\n",
                "This starts to get complicated when you have fields with commas and tabs and newlines in\n",
                "them (which you inevitably do). For this reason, it’s pretty much always a mistake to try to\n",
                "parse them yourself. Instead, you should use Python’s csv module (or the pandas library).\n",
                "\n",
                "For technical reasons that you should feel free to blame on Microsoft, you should always\n",
                "work with csv files in binary mode by including a b after the r or w (see Stack Overflow).\n",
                "\n",
                "If your file has no headers (which means you probably want each row as a list, and\n",
                "which places the burden on you to know what’s in each column), you can use csv.reader\n",
                "to iterate over the rows, each of which will be an appropriately split list."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Date : 6/20/2014 Symbol: AAPL Closing Price: 90.91\n",
                        "Date : 6/20/2014 Symbol: MSFT Closing Price: 41.68\n",
                        "Date : 6/20/2014 Symbol: FB Closing Price: 64.5\n",
                        "Date : 6/19/2014 Symbol: AAPL Closing Price: 91.86\n",
                        "Date : 6/19/2014 Symbol: MSFT Closing Price: 41.51\n",
                        "Date : 6/19/2014 Symbol: FB Closing Price: 64.34\n"
                    ]
                }
            ],
            "source": [
                "# if we have tab delimited files we can process them like this \n",
                "\n",
                "import  csv\n",
                "def process(date , symbol , closing_price):\n",
                "    print(f'Date : {date} Symbol: {symbol} Closing Price: {closing_price}')\n",
                "\n",
                "with open('stock_prices.txt', 'r') as f:\n",
                "    reader = csv.reader(f, delimiter='\\t')\n",
                "    for row in reader:\n",
                "        date = row[0]\n",
                "        symbol = row[1]\n",
                "        closing_price = float(row[2])\n",
                "        process(date, symbol, closing_price)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "If your file has headers:\n",
                "```csv\n",
                "date:symbol:closing_price\n",
                "6/20/2014:AAPL:90.91\n",
                "6/20/2014:MSFT:41.68\n",
                "6/20/2014:FB:64.5\n",
                "```\n",
                "you can either skip the header row (with an initial call to reader.next()) or get each row\n",
                "as a dict (with the headers as keys) by using csv.DictReader:\n",
                "```python\n",
                "with open('colon_delimited_stock_prices.txt', 'rb') as f:\n",
                "    reader = csv.DictReader(f, delimiter=':')\n",
                "    for row in reader:\n",
                "        date = row[\"date\"]\n",
                "        symbol = row[\"symbol\"]\n",
                "        closing_price = float(row[\"closing_price\"])\n",
                "        process(date, symbol, closing_price)\n",
                "```\n",
                "Even if your file doesn’t have headers you can still use DictReader by passing it the keys\n",
                "as a fieldnames parameter.\n",
                "\n",
                "You can similarly write out delimited data using csv.writer:\n",
                "\n",
                "```python \n",
                "today_prices = { 'AAPL' : 90.91, 'MSFT' : 41.68, 'FB' : 64.5 }\n",
                "with open('comma_delimited_stock_prices.txt','wb') as f:\n",
                "    writer = csv.writer(f, delimiter=',')\n",
                "    for stock, price in today_prices.items():\n",
                "        writer.writerow([stock, price])\n",
                "\n",
                "```\n",
                "\n",
                "csv.writer will do the right thing if your fields themselves have commas in them. Your\n",
                "own hand-rolled writer probably won’t. \n",
                "\n",
                "For example, if you attempt:\n",
                "```python\n",
                "results = [[\"test1\", \"success\", \"Monday\"],\n",
                "[\"test2\", \"success, kind of\", \"Tuesday\"],\n",
                "[\"test3\", \"failure, kind of\", \"Wednesday\"],\n",
                "[\"test4\", \"failure, utter\", \"Thursday\"]]\n",
                "# don't do this!\n",
                "\n",
                "with open('bad_csv.txt', 'wb') as f:\n",
                "    for row in results:\n",
                "    f.write(\",\".join(map(str, row))) # might have too many commas in it!\n",
                "    f.write(\"\\n\") # row might have newlines as well!\n",
                "```\n",
                "\n",
                "You will end up with a csv file that looks like:\n",
                "```csv\n",
                "test1,success,Monday\n",
                "test2,success, kind of,Tuesday\n",
                "test3,failure, kind of,Wednesday\n",
                "test4,failure, utter,Thursday\n",
                "```\n",
                "and that no one will ever be able to make sense of."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "base",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
